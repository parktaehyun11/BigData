{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vector\n",
    "- spark에서 type field를 통해 vector 종류 식별\n",
    "    - dense vector (1)\n",
    "    - sparse vector (0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dense vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.  2.1 3. ]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "dv = np.array([1.0,2.1,3])\n",
    "print (dv)\n",
    "print (type(dv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0,2.1,3.0]\n",
      "<class 'pyspark.mllib.linalg.DenseVector'>\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.linalg import Vectors\n",
    "\n",
    "dvmllib = Vectors.dense([1.0,2.1,3])\n",
    "print (dvmllib)\n",
    "print (type(dvmllib))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0,2.1,3.0]\n"
     ]
    }
   ],
   "source": [
    "dvlml = Vectors.dense([1.0,2.1,3])\n",
    "print (dvlml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 2.1 3.0 "
     ]
    }
   ],
   "source": [
    "for e in dvlml:\n",
    "    print (e, end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sparse vector\n",
    "- 실제 값이 없는 요소, '0'을 제거하여 만든 vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1차원 dense vector\n",
    "    - [160, 69, 24]\n",
    "- sparse vector\n",
    "    - 3-컬럼 갯수, [0,1,2]-값이 있는 컬럼 [160.0, 69.0, 24.0]-실제 값\n",
    "    - (3,[0,1,2],[160.0, 69.0, 24.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,[1,2],[1.0,3.0])\n",
      "[0. 1. 3.]\n"
     ]
    }
   ],
   "source": [
    "sv1 = Vectors.sparse(3,[1,2],[1.0,3.0])\n",
    "print (sv1)\n",
    "print (sv1.toArray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 2]\n",
      " [0 0 3]\n",
      " [4 5 6]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sps\n",
    "row = np.array([0,0,1,2,2,2])\n",
    "col = np.array([0,2,2,0,1,2])\n",
    "data = np.array([1,2,3,4,5,6,])\n",
    "mtx = sps.csc_matrix((data,(row,col)), shape=(3,3))\n",
    "print(mtx.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [2., 3., 0., 0.],\n",
       "       [0., 0., 5., 0.],\n",
       "       [0., 4., 6., 0.],\n",
       "       [0., 0., 7., 0.],\n",
       "       [0., 0., 0., 8.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.mllib.linalg import Matrix, Matrices\n",
    "dm = Matrices.dense(6,4,[1,2,0,0,0,0,0,3,0,4,0,0,0,0,5,6,7,0,0,0,0,0,0,8])\n",
    "dm.toArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseMatrix(6, 4, [0, 2, 4, 7, 8], [0, 1, 1, 3, 2, 3, 4, 5], [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0], False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm.toSparse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseMatrix(6, 4, [1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, ..., 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0], False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 X 2 CSCMatrix\n",
      "(0,0) 9.0\n",
      "(2,1) 6.0\n",
      "(1,1) 8.0\n"
     ]
    }
   ],
   "source": [
    "sm = Matrices.sparse(3,2,[0,1,3],[0,2,1],[9,6,8])\n",
    "print (sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseMatrix([[9., 0.],\n",
      "             [0., 8.],\n",
      "             [0., 6.]])\n"
     ]
    }
   ],
   "source": [
    "d = sm.toDense()\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = [[1.0,2.0,3.0],[1.1,2.1,3.1],[1.2,2.2,3.2]]\n",
    "my = spark.sparkContext.parallelize(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.0, 2.0, 3.0], [1.1, 2.1, 3.1], [1.2, 2.2, 3.2]]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.mllib.linalg.distributed.RowMatrix'>\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.linalg.distributed import RowMatrix\n",
    "rm = RowMatrix(my) # 리스트를 묶어 여러 행으로 구성된 벡터를 생성\n",
    "print (type(rm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DenseVector([1.0, 2.0, 3.0]),\n",
       " DenseVector([1.1, 2.1, 3.1]),\n",
       " DenseVector([1.2, 2.2, 3.2])]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rm.rows.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labeled Point\n",
    "- label, features 로 구성\n",
    "    - label: supervised learning에서 '구분 값'으로 사용, data type:double"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0,[1.0,2.0,3.0])\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "print (LabeledPoint(1.0,[1.0,2.0,3.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1992.0,(10,[0,1,2],[3.0,5.5,10.0]))\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "\n",
    "print (LabeledPoint(1992,Vectors.sparse(10,{0:3.0, 1:5.5, 2:10.0}))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([1.0, 2.1, 3.0])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dvmllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabeledPoint(1.0, [1.0,2.1,3.0])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "LabeledPoint(1.0,dvmllib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.mllib.linalg.DenseVector"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dvlml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabeledPoint(1.0, [1.0,2.1,3.0])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "LabeledPoint(1.0, dvlml)\n",
    "#LabeledPoint(1.0, Vectors.fromML(dvlml))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
