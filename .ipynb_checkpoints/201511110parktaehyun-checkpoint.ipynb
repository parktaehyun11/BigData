{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1번"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "myList = ['When I find myself in times of trouble',\n",
    "'Mother Mary comes to me',\n",
    "'Speaking words of wisdom, let it be',\n",
    "'And in my hour of darkness',\n",
    "'She is standing right in front of me',\n",
    "'Speking words of wisdom, let it be',\n",
    "'Let it be',\n",
    "'Let it be',\n",
    "'Let it be',\n",
    "'Let it be',\n",
    "'Whisper words of wisdom, let it be'\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "myRdd = spark.sparkContext.parallelize(myList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['When I find myself in times of trouble',\n",
       " 'Mother Mary comes to me',\n",
       " 'Speaking words of wisdom, let it be',\n",
       " 'And in my hour of darkness',\n",
       " 'She is standing right in front of me']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myRdd.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 IT\n",
      "7 LET\n",
      "7 BE\n",
      "3 WORDS\n",
      "3 WISDOM,\n",
      "2 ME\n",
      "1 FIND\n",
      "1 TROUBLE\n",
      "1 MOTHER\n",
      "1 MARY\n",
      "1 MY\n",
      "1 SHE\n",
      "1 STANDING\n",
      "1 SPEKING\n",
      "1 WHEN\n",
      "1 COMES\n",
      "1 FRONT\n",
      "1 WHISPER\n",
      "1 MYSELF\n",
      "1 TIMES\n",
      "1 SPEAKING\n",
      "1 AND\n",
      "1 HOUR\n",
      "1 DARKNESS\n",
      "1 RIGHT\n"
     ]
    }
   ],
   "source": [
    "stopwords = ['I','is','in','to','in','of']\n",
    "myRdd_stop = myRdd.flatMap(lambda x:x.split()).filter(lambda x: x not in stopwords)\n",
    "upperRDD =myRdd_stop.map(lambda x: x.upper())\n",
    "wc = upperRDD.map(lambda x:(x,1)).reduceByKey(lambda x,y:x+y).map(lambda x:(x[1],x[0])).sortByKey(False).collect()\n",
    "for i in wc:\n",
    "    print (i[0],i[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "myList1 = [\"201411111,lim js,휴먼,58,165\",\n",
    "          \"201811111,kim js,휴먼,79,175\",\n",
    "          \"201211111,lee js,휴먼,65,180\",\n",
    "          \"201511111,choi js,컴과,66,163\",\n",
    "          \"201911111,yoon js,컴과,65,158\",\n",
    "          \"201311111,park js,경영,100,160\",\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['201411111,lim js,휴먼,58,165', '201811111,kim js,휴먼,79,175', '201211111,lee js,휴먼,65,180', '201511111,choi js,컴과,66,163', '201911111,yoon js,컴과,65,158', '201311111,park js,경영,100,160']\n"
     ]
    }
   ],
   "source": [
    "myRdd1 = spark.sparkContext.parallelize(myList1)\n",
    "print (myRdd1.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lim js 127.86938795999998\n",
      "kim js 174.16692497999998\n",
      "lee js 143.3019003\n",
      "choi js 145.50654491999998\n",
      "yoon js 143.3019003\n",
      "park js 220.46446199999997\n"
     ]
    }
   ],
   "source": [
    "weight = myRdd1.map(lambda x:x.split(',')).map(lambda x:(x[1],float(x[3]))).collect()\n",
    "for i in weight:\n",
    "    print (i[0],i[1]*2.20464462)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "컴과 131.0\n",
      "경영 100.0\n",
      "휴먼 202.0\n"
     ]
    }
   ],
   "source": [
    "Q2_2 = myRdd1.map(lambda x:x.split(',')).map(lambda x:(x[2],float(x[3]))).reduceByKey(lambda x,y:x+y).collect()\n",
    "for i in Q2_2:\n",
    "    print (i[0],i[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=myRdd1.map(lambda x:x.split(',')).map(lambda x: (x[1],int(x[4])))\n",
    "a=myRdd1.map(lambda x:x.split(',')).map(lambda x: (x[1],int(x[4])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lim js', 165),\n",
       " ('kim js', 175),\n",
       " ('lee js', 180),\n",
       " ('choi js', 163),\n",
       " ('yoon js', 158),\n",
       " ('park js', 160)]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "bicycle = spark.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load('data/bicycle.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+\n",
      "|               date|count|\n",
      "+-------------------+-----+\n",
      "|2018-01-01 00:00:00| 4950|\n",
      "|2018-01-02 00:00:00| 7136|\n",
      "|2018-01-03 00:00:00| 7156|\n",
      "|2018-01-04 00:00:00| 7102|\n",
      "|2018-01-05 00:00:00| 7705|\n",
      "+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bicycle.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "bicycle = bicycle\\\n",
    "    .withColumn('year', F.year('date'))\\\n",
    "    .withColumn('quarter', F.quarter('date'))\\\n",
    "    .withColumn('month', F.month('date'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+-------+-------+-------+\n",
      "|year|      1|      2|      3|      4|\n",
      "+----+-------+-------+-------+-------+\n",
      "|2018| 795769|2860617|3585513|2882975|\n",
      "|2019|1871935|   null|   null|   null|\n",
      "+----+-------+-------+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bicycle.groupBy('year').pivot('quarter').agg({\"count\":\"sum\"}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+----+-----+-------+\n",
      "|               date|count|year|month|quarter|\n",
      "+-------------------+-----+----+-----+-------+\n",
      "|2018-01-01 00:00:00| 4950|2018|    1|      1|\n",
      "|2018-01-02 00:00:00| 7136|2018|    1|      1|\n",
      "|2018-01-03 00:00:00| 7156|2018|    1|      1|\n",
      "|2018-01-04 00:00:00| 7102|2018|    1|      1|\n",
      "|2018-01-05 00:00:00| 7705|2018|    1|      1|\n",
      "+-------------------+-----+----+-----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bicycle.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+------+------+------+------+-------+-------+-------+-------+-------+------+------+\n",
      "|year|     1|     2|     3|     4|     5|      6|      7|      8|      9|     10|    11|    12|\n",
      "+----+------+------+------+------+------+-------+-------+-------+-------+-------+------+------+\n",
      "|2018|164367|168741|462661|687885|965609|1207123|1100015|1037505|1447993|1420621|961532|500822|\n",
      "|2019|495573|471543|904819|  null|  null|   null|   null|   null|   null|   null|  null|  null|\n",
      "+----+------+------+------+------+------+-------+-------+-------+-------+-------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bicycle.groupBy('year').pivot('month').agg({\"count\":\"sum\"}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
