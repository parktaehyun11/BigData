{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": "stopwords = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your','I','be',\\\n             'is','am','are','the','for','a','an','at','this','ther','that','to','by','in','on']"
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Overwriting data/ds_bigdata_stopwordsex.txt\n"
    }
   ],
   "source": "%%writefile data/ds_bigdata_stopwordsex.txt\nHello, my name is park.\nThis is a text which is written by park.\nI am going to talk about big data.\nBig data is going to be important.\nWe live in a big data world.\nEverything is data in this era. \nSpark is a tool to use big data."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## python 사용"
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Hello, 1\nmy 1\nname 1\nis 6\npark. 2\nThis 1\na 3\ntext 1\nwhich 1\nwritten 1\nby 1\nI 1\nam 1\ngoing 2\nto 3\ntalk 1\nabout 1\nbig 3\ndata. 2\nBig 1\ndata 3\nbe 1\nimportant. 1\nWe 1\nlive 1\nin 2\nworld. 1\nEverything 1\nthis 1\nera. 1\nSpark 1\ntool 1\nuse 1\n"
    }
   ],
   "source": "import os\nf=open(os.path.join(\"data\", \"ds_bigdata_stopwordsex.txt\"))\nd = dict()\nfor sent in f.readlines():\n    for w in sent.split():\n        if w not in d:\n            d[w]=1\n        else:\n            d[w]=d[w]+1\n            \nfor key, value in d.items():\n    print (key, value)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ""
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ""
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['Hello, my name is park.',\n 'This is a text which is written by park.',\n 'I am going to talk about big data.',\n 'Big data is going to be important.',\n 'We live in a big data world.',\n 'Everything is data in this era. ',\n 'Spark is a tool to use big data.']"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": "myRdd = spark.sparkContext.textFile(os.path.join(\"data\",\"ds_bigdata_stopwordsex.txt\"))\nmyRdd.collect()"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['Hello,',\n 'my',\n 'name',\n 'is',\n 'park.',\n 'This',\n 'is',\n 'a',\n 'text',\n 'which',\n 'is',\n 'written',\n 'by',\n 'park.',\n 'I',\n 'am',\n 'going',\n 'to',\n 'talk',\n 'about',\n 'big',\n 'data.',\n 'Big',\n 'data',\n 'is',\n 'going',\n 'to',\n 'be',\n 'important.',\n 'We',\n 'live',\n 'in',\n 'a',\n 'big',\n 'data',\n 'world.',\n 'Everything',\n 'is',\n 'data',\n 'in',\n 'this',\n 'era.',\n 'Spark',\n 'is',\n 'a',\n 'tool',\n 'to',\n 'use',\n 'big',\n 'data.']"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": "myRdd_stop = myRdd.flatMap(lambda x:x.split())\nmyRdd_stop.collect()"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['Hello,',\n 'name',\n 'park.',\n 'text',\n 'which',\n 'written',\n 'park.',\n 'going',\n 'talk',\n 'about',\n 'big',\n 'data.',\n 'Big',\n 'data',\n 'going',\n 'important.',\n 'live',\n 'big',\n 'data',\n 'world.',\n 'Everything',\n 'data',\n 'era.',\n 'Spark',\n 'tool',\n 'use',\n 'big',\n 'data.']"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": "myRdd_stop1 = myRdd_stop.filter(lambda x: x.lower() not in stopwords)\nmyRdd_stop1.collect()"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[('Big', 1),\n ('Everything', 1),\n ('Hello,', 1),\n ('Spark', 1),\n ('about', 1),\n ('big', 3),\n ('data', 3),\n ('data.', 2),\n ('era.', 1),\n ('going', 2),\n ('important.', 1),\n ('live', 1),\n ('name', 1),\n ('park.', 2),\n ('talk', 1),\n ('text', 1),\n ('tool', 1),\n ('use', 1),\n ('which', 1),\n ('world.', 1),\n ('written', 1)]"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": "myRdd_stop2 = myRdd_stop1.map(lambda x:(x,1)).groupByKey().mapValues(sum).sortByKey(True)\nmyRdd_stop2.collect()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
