{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 201511110 박태현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1번"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "_trainDf = spark.read.format('com.databricks.spark.csv')\\\n",
    "    .options(header='false', inferschema='true')\\\n",
    "    .load(os.path.join(\"data\",\"testdata.manual.2009.06.14.csv\"))\n",
    "df = _trainDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|_c0|count|\n",
      "+---+-----+\n",
      "|  4|  182|\n",
      "|  2|  139|\n",
      "|  0|  177|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('_c0').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"label\",_trainDf['_c0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+--------------------+-------+--------+--------------------+-----+\n",
      "|_c0|_c1|                 _c2|    _c3|     _c4|                 _c5|label|\n",
      "+---+---+--------------------+-------+--------+--------------------+-----+\n",
      "|  4|  3|Mon May 11 03:17:...|kindle2|  tpryan|@stellargirl I lo...|    4|\n",
      "|  4|  4|Mon May 11 03:18:...|kindle2|  vcu451|Reading my kindle...|    4|\n",
      "|  4|  5|Mon May 11 03:18:...|kindle2|  chadfu|Ok, first assesme...|    4|\n",
      "|  4|  6|Mon May 11 03:19:...|kindle2|   SIX15|@kenburbary You'l...|    4|\n",
      "|  4|  7|Mon May 11 03:21:...|kindle2|yamarama|@mikefish  Fair e...|    4|\n",
      "+---+---+--------------------+-------+--------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StopWordsRemover\n",
    "stop = StopWordsRemover(inputCol=\"wordsReg\", outputCol=\"nostops\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StopWordsRemover_e874b4386c90"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords=list()\n",
    "_stopwords=stop.getStopWords()\n",
    "for e in _stopwords:\n",
    "    stopwords.append(e)\n",
    "\n",
    "_mystopwords=[\":)\",\"of\", \"@stellargirl\",\"@kenburbary\"]\n",
    "for e in _mystopwords:\n",
    "    stopwords.append(e)\n",
    "stop.setStopWords(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i\n",
      "me\n",
      "my\n",
      "myself\n",
      "we\n",
      "our\n",
      "ours\n",
      "ourselves\n",
      "you\n",
      "your\n",
      "yours\n",
      "yourself\n",
      "yourselves\n",
      "he\n",
      "him\n",
      "his\n",
      "himself\n",
      "she\n",
      "her\n",
      "hers\n",
      "herself\n",
      "it\n",
      "its\n",
      "itself\n",
      "they\n",
      "them\n",
      "their\n",
      "theirs\n",
      "themselves\n",
      "what\n",
      "which\n",
      "who\n",
      "whom\n",
      "this\n",
      "that\n",
      "these\n",
      "those\n",
      "am\n",
      "is\n",
      "are\n",
      "was\n",
      "were\n",
      "be\n",
      "been\n",
      "being\n",
      "have\n",
      "has\n",
      "had\n",
      "having\n",
      "do\n",
      "does\n",
      "did\n",
      "doing\n",
      "a\n",
      "an\n",
      "the\n",
      "and\n",
      "but\n",
      "if\n",
      "or\n",
      "because\n",
      "as\n",
      "until\n",
      "while\n",
      "of\n",
      "at\n",
      "by\n",
      "for\n",
      "with\n",
      "about\n",
      "against\n",
      "between\n",
      "into\n",
      "through\n",
      "during\n",
      "before\n",
      "after\n",
      "above\n",
      "below\n",
      "to\n",
      "from\n",
      "up\n",
      "down\n",
      "in\n",
      "out\n",
      "on\n",
      "off\n",
      "over\n",
      "under\n",
      "again\n",
      "further\n",
      "then\n",
      "once\n",
      "here\n",
      "there\n",
      "when\n",
      "where\n",
      "why\n",
      "how\n",
      "all\n",
      "any\n",
      "both\n",
      "each\n",
      "few\n",
      "more\n",
      "most\n",
      "other\n",
      "some\n",
      "such\n",
      "no\n",
      "nor\n",
      "not\n",
      "only\n",
      "own\n",
      "same\n",
      "so\n",
      "than\n",
      "too\n",
      "very\n",
      "s\n",
      "t\n",
      "can\n",
      "will\n",
      "just\n",
      "don\n",
      "should\n",
      "now\n",
      "i'll\n",
      "you'll\n",
      "he'll\n",
      "she'll\n",
      "we'll\n",
      "they'll\n",
      "i'd\n",
      "you'd\n",
      "he'd\n",
      "she'd\n",
      "we'd\n",
      "they'd\n",
      "i'm\n",
      "you're\n",
      "he's\n",
      "she's\n",
      "it's\n",
      "we're\n",
      "they're\n",
      "i've\n",
      "we've\n",
      "you've\n",
      "they've\n",
      "isn't\n",
      "aren't\n",
      "wasn't\n",
      "weren't\n",
      "haven't\n",
      "hasn't\n",
      "hadn't\n",
      "don't\n",
      "doesn't\n",
      "didn't\n",
      "won't\n",
      "wouldn't\n",
      "shan't\n",
      "shouldn't\n",
      "mustn't\n",
      "can't\n",
      "couldn't\n",
      "cannot\n",
      "could\n",
      "here's\n",
      "how's\n",
      "let's\n",
      "ought\n",
      "that's\n",
      "there's\n",
      "what's\n",
      "when's\n",
      "where's\n",
      "who's\n",
      "why's\n",
      "would\n",
      ":)\n",
      "of\n",
      "@stellargirl\n",
      "@kenburbary\n"
     ]
    }
   ],
   "source": [
    "for e in stop.getStopWords():\n",
    "    print (e,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2번"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "rdd=spark.sparkContext\\\n",
    "    .textFile(os.path.join('data','diabetes.tab.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AGE\\tSEX\\tBMI\\tBP\\tS1\\tS2\\tS3\\tS4\\tS5\\tS6\\tY',\n",
       " '59\\t2\\t32.1\\t101\\t157\\t93.2\\t38\\t4\\t4.8598\\t87\\t151',\n",
       " '48\\t1\\t21.6\\t87\\t183\\t103.2\\t70\\t3\\t3.8918\\t69\\t75']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "myRdd=rdd.map(lambda x:x.split('\\t'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['AGE', 'SEX', 'BMI', 'BP', 'S1', 'S2', 'S3', 'S4', 'S5', 'S6', 'Y'],\n",
       " ['59', '2', '32.1', '101', '157', '93.2', '38', '4', '4.8598', '87', '151'],\n",
       " ['48', '1', '21.6', '87', '183', '103.2', '70', '3', '3.8918', '69', '75']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myRdd.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "myDf=spark.createDataFrame(myRdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_1', '_2', '_3', '_4', '_5', '_6', '_7', '_8', '_9', '_10', '_11']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myDf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abalone['Male'] = (abalone['SEX']==).astype(int)\n",
    "abalone['Female'] = (abalone['SEX']=='F').astype(int)\n",
    "abalone['Infant'] = (abalone['SEX']=='I').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "_trainDf3 = spark.read.format('com.databricks.spark.csv')\\\n",
    "    .options(header='false', inferschema='true')\\\n",
    "    .load(os.path.join(\"data\",\"ds9_xy.csv\"))\n",
    "df3 = _trainDf3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_c0', '_c1']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.discrete.discrete_model as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+\n",
      "| _c0|_c1|\n",
      "+----+---+\n",
      "|0.24|  0|\n",
      "|0.25|  0|\n",
      "|0.28|  1|\n",
      "| 0.3|  1|\n",
      "|0.33|  1|\n",
      "|0.35|  1|\n",
      "|0.36|  0|\n",
      "|0.36|  1|\n",
      "|0.36|  0|\n",
      "|0.36|  1|\n",
      "| 0.4|  0|\n",
      "| 0.4|  1|\n",
      "|0.41|  0|\n",
      "|0.42|  1|\n",
      "|0.43|  0|\n",
      "|0.47|  1|\n",
      "|0.51|  1|\n",
      "|0.53|  1|\n",
      "|0.56|  0|\n",
      "|0.57|  0|\n",
      "+----+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_c0', '_c1']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x=np.array([1,2,3,4])\n",
    "y=np.array([6,5,7,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
